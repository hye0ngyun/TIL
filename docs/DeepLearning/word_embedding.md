# 워드 임베딩(Word Embedding)

- 워드 임베딩은 단어를 밀집 벡터로 표현하는 방법이다.
- 밀집 벡터로 표현하는 이유는 단어간 유사도 같은 계산이 가능하다.
- 원 핫 인코딩을 하지 않는 이유는 유사도 계산을 못하고 클래스 수 만큼 차원이 늘어나서 차원의 저주에 빠져 속도가 매우 느려진다.

## 워드 임베딩 방법

- 카운트 기반 벡터화: LSA, HAL
- 예측 기반 벡터화: NNLM, RNNLM, Word2Vec, FastText
- 카운트 기반과 예측 기반 두가지를 사용하는 벡터화: GloVe
