{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. 출력층 - 소프트맥스",
      "provenance": [],
      "authorship_tag": "ABX9TyP5LA6atLionYKIQfNxVDwn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hye0ngyun/TIL/blob/main/4_%EC%B6%9C%EB%A0%A5%EC%B8%B5_%EC%86%8C%ED%94%84%ED%8A%B8%EB%A7%A5%EC%8A%A4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rla2sULxbH5l"
      },
      "source": [
        "# 출력층 설계하기\n",
        "- 신경망은 분류와 회귀 문제 모두에 이용할 수 있다.\n",
        "- 회귀: 항등 함수(identify funtion)\n",
        "- 분류: 소프트맥스 함수(softmax funtion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvGY-owMZmWi"
      },
      "source": [
        "# 소프트맥스\n",
        "$$\n",
        "y_k = \\frac{e^{a_k}}{\\sum_{i=0}^{n-1} e^{a_i}}\n",
        "$$\n",
        "- 소프트맥스 함수의 분자는 입력 신호 ${a_k}$의 지수함수, 분모는 모든 입력 신호의 지수 함수의 합이다.\n",
        "- 즉, 입력 신호를 모두 더한 값이 분모고 입력 하나가 분자이므로 각 분자별(클래스별) 영향도(분류기준)를 알 수 있다.\n",
        "- 예를 들어 소프트맥스를 거친 뒤 가장 높은 값을 가지고 있는 클래스로 예측할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTJW2bAba8BP"
      },
      "source": [
        "## 소프트맥스 계산 과정 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MM9IkNltaMeZ",
        "outputId": "68b4ddc3-41e3-4e35-9fdf-682c43f49c07"
      },
      "source": [
        "import numpy as np\n",
        "a = np.array([0.3, 2.9, 4.0])\n",
        "\n",
        "exp_a = np.exp(a) # 지수함수\n",
        "print(exp_a)\n",
        "\n",
        "sum_exp_a = np.sum(exp_a) # 지수함수의 합\n",
        "print(sum_exp_a)\n",
        "\n",
        "y = exp_a / sum_exp_a\n",
        "print(y)\n",
        "# 소프트맥스를 거친 값들의 합은 항상 1\n",
        "print(y.sum())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1.34985881 18.17414537 54.59815003]\n",
            "74.1221542101633\n",
            "[0.01821127 0.24519181 0.73659691]\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiOYbrjCa4eh"
      },
      "source": [
        "## 소프트맥스 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THNNGgLyaRAS"
      },
      "source": [
        "def softmax(a):\n",
        "  exp_a = np.exp(a)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a / sum_exp_a\n",
        "  return y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9_VoWV4fzPq",
        "outputId": "504f91f7-f302-4ca3-a3a4-575a50b147ba"
      },
      "source": [
        "a = np.array([0.3, 2.9, 4.0])\n",
        "softmax(a)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01821127, 0.24519181, 0.73659691])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxlLoqvGa3xv"
      },
      "source": [
        "## 소프트맥스 함수 구현 시 주의점\n",
        "- 지수함수를 이용하므로 입력으로 매우 큰값이 들어올 경우 오버플로 발생 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qplf_SDvdd3Y",
        "outputId": "fb877bec-daa9-4711-fd6d-9a3c9ac93169"
      },
      "source": [
        "a = np.array([1010, 1000, 990])\n",
        "print(np.exp(a)) # [inf inf inf]\n",
        "print(np.exp(a) / np.sum(np.exp(a))) # [nan nan nan]\n",
        "\n",
        "c = np.max(a) # c = 1010(최댓값)\n",
        "print(a - c) # [  0, -10, -20]\n",
        "\n",
        "# 계산 가능\n",
        "print(np.exp(a-c) / np.sum(np.exp(a-c))) # [9.99954600e-01, 4.53978686e-05, 2.06106005e-09]\n",
        "# 전체 합은 여전히 1\n",
        "print(np.sum(np.exp(a-c) / np.sum(np.exp(a-c))))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[inf inf inf]\n",
            "[nan nan nan]\n",
            "[  0 -10 -20]\n",
            "[9.99954600e-01 4.53978686e-05 2.06106005e-09]\n",
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5KITBHEe5M1"
      },
      "source": [
        "# 개선된 소프트맥스 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LdpqN2WeC57"
      },
      "source": [
        "def softmax(a):\n",
        "  c = a.max()\n",
        "  exp_a = np.exp(a - c)\n",
        "  sum_exp_a = np.sum(exp_a)\n",
        "  y = exp_a / sum_exp_a\n",
        "  return y\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq9Q4VLIflHq",
        "outputId": "a5c15199-7b9f-4025-c51f-91bb00a0c106"
      },
      "source": [
        "a = np.array([1010, 1000, 990])\n",
        "softmax(a)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3POHF-cfohP"
      },
      "source": [
        "## 소프트맥스 함수의 특징\n",
        "- 소프트맥스 함수는 앞에서 설명한것과 출력이 0에서 1.0 사이의 실수이며, 출력의 총합은 1이다.\n",
        "- 출력 총합이 1이 된다는것은 소프트맥스 함수의 출력을 **확률**로 해석할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1vbfS7khfou",
        "outputId": "2221d298-3892-472a-c6cd-3f16caa32152"
      },
      "source": [
        "a = np.array([0.3, 2.9, 4.0])\n",
        "y = softmax(a)\n",
        "y"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01821127, 0.24519181, 0.73659691])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQHj467xh60f"
      },
      "source": [
        "- 위 출력결과를 보면 0번 클래스는 1.8%, 1번클래스는 24%, 2번클래스는 73%로 확인할 수 있다.\n",
        "- 즉, 소프트맥스 함수를 이용해서 문제를 **확률적(통계적)**으로 대응 가능하다.\n",
        "- 소프트맥스는 항등함수로 적용전과 후 원소의 대소관계는 변하지 않는다. -> **단조함수**이다.\n",
        "  - 단조함수란 함수 적용전과 후의 대소관계가 동일한 함수를 뜻한다.\n",
        "- 결과적으로 신경망으로 **분류**할 떄는 출력층의 소프트맥스 함수를 **생략**해도 된다.\n",
        "- 그러나 신경망을 **학습**시킬 때는 출력층에서 소프트맥스 함수를 **사용**한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kiSHPm9i7Ug"
      },
      "source": [
        "## 출력층의 뉴런 수\n",
        "- 출력층의 뉴런 수는 푸는 문제(회귀, 분류 등)에 따라 적절히 정해야한다.\n",
        "- 분류에서는 분류하고 싶은 클래스의 수로 설정하는것이 일반적이다.\n",
        "- 예를 들어 mnist라는 숫자 손글씨 예측 문제의 경우 숫자 0~9까지 10개의 뉴런을 출력층의 뉴런 개수로 정한다."
      ]
    }
  ]
}